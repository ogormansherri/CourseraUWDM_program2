{
 "metadata": {
  "name": "assignment2.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Coursera Data Mining Class Assignment 2 <br>\n",
      "\n",
      "Database Assignment: Simple In-Database Text Analytics "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Student: Sherri Verdugo<br>\n",
      "Date: July 15, 2014"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1A<br>\n",
      "(a) select: Write a query that is equivalent to the following relational algebra expression:     \u03c310398_txt_earn(frequency)\n",
      "<br><br>\n",
      "What to turn in: Run your query against your local database and determine the number of records returned. On the assignment page, upload a text file, select.txt, which includes a single line with the number of records. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "sql = \"select count(*) from (select * from frequency f where f.docid = '10398_txt_earn');\"  ## specify your SQL statement here\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "with open('select.txt', 'wb') as output:\n",
      "    output.write('138')\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(138,)]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1B <br>\n",
      " (b) select project: Write a SQL statement that is equivalent to the following relational algebra expression. $\\pi$_term($\\sigma$docid=10398_txt_earn and count=1(frequency))<br><br>\n",
      "\n",
      "What to turn in: Run your query against your local database and determine the number of records returned as described above. upload a text file select_project.txt which states the number of records."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "sql = \"select count(*) from (select term from frequency f where f.docid = '10398_txt_earn' and f.count = 1);\"  ## specify your SQL statement here\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "with open('select_project.txt', 'wb') as output:\n",
      "    output.write('110')\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(110,)]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1C <br>\n",
      "(c) union: Write a SQL statement that is equivalent to the following relational algebra expression. (Hint: you can use the UNION keyword in SQL)\n",
      "<br>\n",
      "\u03c0term(\u03c3docid=10398_txt_earn and count=1(frequency)) U \u03c0term(\u03c3docid=925_txt_trade and count=1(frequency))\n",
      "<br><br>\n",
      "What to turn in: Run your query against your local database and determine the number of records returned as described above. In your browser, upload a text file union.txt with a single line containing the number of records."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"\"\"select count(*) from (select term from frequency f1 where f1.docid='10398_txt_earn' and f1.count=1 union select term from frequency f2 where f2.docid='925_txt_trade' and f2.count=1);\n",
      "\"\"\"\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"union.txt\", \"wb\")\n",
      "\n",
      "file.write(\"324\")\n",
      "\n",
      "file.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(324,)]\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1D <br> \n",
      "(d) count: Write a SQL statement to count the number of documents containing the word \"parliament\"\n",
      "<br><br>\n",
      "What to turn in: Run your query against your local database and determine the count returned as described above. On the assignment page, upload a text file count.txt with a single line containing the number of records."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"select count(*) from (select * from frequency f where f.term = 'parliament')\"\n",
      "\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"count.txt\", \"wb\")\n",
      "\n",
      "file.write(\"15\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(15,)]\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1E<br> \n",
      "(e) big documents Write a SQL statement to find all documents that have more than 300 total terms, including duplicate terms. (Hint: You can use the HAVING clause, or you can use a nested query. Another hint: Remember that the count column contains the term frequencies, and you want to consider duplicates.) (docid, term_count)\n",
      "<br><br>\n",
      "What to turn in: Run your query against your local database and determine the number of records returned as described above. On the assignment page, upload a text file big_documents.txt with a single line containing the number of records.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"select count(*) from (select docid, sum(count) from frequency f group by f.docid having sum(f.count) > 300);\"\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"big_documents.txt\", \"wb\")\n",
      "\n",
      "file.write(\"107\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(107,)]\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1F <br>\n",
      "(f) two words: Write a SQL statement to count the number of unique documents that contain both the word 'transactions' and the word 'world'.\n",
      "<br><br>\n",
      "What to turn in: Run your query against your local database and determine the number of records returned as described above. On the assignment page, upload a text file two_words.txt with a single line containing the number of records."
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1g <br>\n",
      "(g) multiply: Express A X B as a SQL query, referring to the class lecture for hints.\n",
      "<br><br>\n",
      "What to turn in: On the assignment page, turn in a text document multiply.txt with a single line containing the value of the cell (2,3)\n",
      "<br><br>\n",
      "Answer: (2, 3, *2874*)\n",
      "\n",
      "<br><br>\n",
      "If you're wondering why this might be a good idea, consider that advanced databases execute queries in parallel automatically. So it can be quite efficient to process a very large sparse matrix --- millions of rows or columns --- in a database. But a word of warning: In a job interview, don't tell them you recommend implementing linear algebra in a database. You won't be wrong, but they won't understand databases as well as you now do, and therefore won't understand when and why this is a good idea. Just say you have done some experiments using databases for analytics, then mention the papers in the reading if they seem incredulous!\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"select count(*) from (select f1.docid from frequency f1 inner join frequency f2 on f1.docid = f2.docid where f1.term = 'transactions' and f2.term='world');\"\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"two_words.txt\", \"wb\")\n",
      "\n",
      "file.write(\"3\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(3,)]\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "from array import *\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"matrix.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"\"\"\n",
      "SELECT a.row_num, b.col_num, SUM(a.value*b.value)\n",
      "FROM a, b\n",
      "WHERE a.col_num = b.row_num\n",
      "GROUP BY a.row_num, b.col_num;\n",
      "\"\"\"\n",
      "\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"multiply.txt\", \"wb\")\n",
      "\n",
      "file.write(\"2874\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0, 10284), (0, 1, 5221), (0, 2, 990), (0, 3, 1320), (0, 4, 234), (1, 0, 9825), (1, 1, 2482), (1, 2, 54), (1, 3, 1269), (1, 4, 1041), (2, 0, 4198), (2, 1, 735), (2, 2, 3954), (2, 3, 2874), (3, 0, 9305), (3, 1, 898), (3, 3, 1881), (3, 4, 201), (4, 0, 3038), (4, 1, 7152), (4, 4, 4083)]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Problem 3: Working with a Term-Document Matrix<br><br>\n",
      "\n",
      "The reuters dataset can be considered a term-document matrix, which is an important representation for text analytics.<br><br>\n",
      "\n",
      "Each row of the matrix is a document vector, with one column for every term in the entire corpus. Naturally, some documents may not contain a given term, so this matrix is rather sparse. The value in each cell of the matrix is the term frequency. (You'd often want this this value to be a weighted term frequency, typically using \"tf-idf\": term frequency - inverse document frequency. But we'll stick with the raw frequency for now.)<br><br>\n",
      "\n",
      "What can you do with the term-document matrix D? One thing you can do is compute the similarity of documents. Just multiply the matrix with its own transpose S = DDT, and you have an (unnormalized) measure of similarity.\n",
      "<br><br>\n",
      "The result is a square document-document matrix, where each cell represents the similarity. Here, similarity is pretty simple: if two documents both contain a term, then the score goes up by the product of the two term frequencies. This score is equivalent to the dot product of the two document vectors.\n",
      "<br><br>\n",
      "To normalize this score to the range 0-1 and to account for relative term frequencies, the cosine similarity is perhaps more useful. The cosine similarity is a measure of the angle between the two document vectors, normalized by magnitude. You just divide the dot product by the magnitude of the two vectors. However, we would need a power function (x^2, x^(1/2)) to compute the magnitude, and sqlite has built-in support for only very basic mathematical functions. It is not hard to extend sqlite to add what you need, but we won't be doing that in this assignment. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1h <br><br>\n",
      "(h) similarity matrix: Write a query to compute the similarity matrix DDT. (Hint: The transpose is trivial -- just join on columns to columns instead of columns to rows.) The query could take some time to run if you compute the entire result. But notice that you don't need to compute the similarity of both (doc1, doc2) and (doc2, doc1) -- they are the same, since similarity is symmetric. If you wish, you can avoid this wasted work by adding a condition of the form a.docid < b.docid to your query. (But the query still won't return immediately if you try to compute every result -- don't expect otherwise.)<br><br>\n",
      "\n",
      "What to turn in: On the assignment website, turn in a text document similarity_matrix.txt that contains a single line giving the similarity of the two documents '10080_txt_crude' and '17035_txt_earn'.<br><br>\n",
      "\n",
      "You can also use this similarity metric to implement some primitive search capabilities. Consider a keyword query that you might type into Google: It's a bag of words, just like a document (typically a keyword query will have far fewer terms than a document, but that's ok).<br><br>\n",
      "\n",
      "So if we can compute the similarity of two documents, we can compute the similarity of a query with a document. You can imagine taking the union of the keywords represented as a small set of (docid, term, count) tuples with the set of all documents in the corpus, then recomputing the similarity matrix and returning the top 10 highest scoring documents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "from array import *\n",
      "import sqlite3\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"\"\"\n",
      "   select A.docid, B.docid, sum(A.count * B.count) from frequency A join frequency B on A.term = B.term where A.docid = '10080_txt_crude' and B.docid = '17035_txt_earn' group by A.docid, B.docid;\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "print cursor.execute(sql).fetchall() \n",
      "\n",
      "file = open(\"similarity_matrix.txt\", \"wb\")\n",
      "\n",
      "file.write(\"19\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'10080_txt_crude', u'17035_txt_earn', 19)]\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Assignment 2: Problem 1h <br><br>\n",
      "\n",
      "Keyword search: Find the best matching document to the keyword query \"washington taxes treasury\". You can add this set of keywords to the document corpus with a union of scalar queries:<br><br>\n",
      "\n",
      "SELECT * FROM frequency<br>\n",
      "UNION<br>\n",
      "SELECT 'q' as docid, 'washington' as term, 1 as count <br>\n",
      "UNION<br>\n",
      "SELECT 'q' as docid, 'taxes' as term, 1 as count<br>\n",
      "UNION <br>\n",
      "SELECT 'q' as docid, 'treasury' as term, 1 as count<br><br>\n",
      "\n",
      "Then, compute the similarity matrix again, but filter for only similarities involving the \"query document\": docid = 'q'. Consider creating a view of this new corpus to simplify things.<br><br>\n",
      "\n",
      "What to turn in: On the assignment page, upload a text document keyword_search.txt that contains a single line giving the maximum similarity score between the query and any document. Your SQL query should return a list of (docid, similarity) pairs, but you will submit a file containing only a single number: the highest score in the list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "from array import *\n",
      "import sqlite3 as lite\n",
      "import sys\n",
      "\n",
      "cursor = sqlite3.connect(\"reuters.db\").cursor()\n",
      "\n",
      "## specify your SQL statement here\n",
      "sql = \"\"\"\n",
      "SELECT a.docid, 1.0*sum(a.count) as sum_count from frequency a\n",
      "WHERE a.term in ('washington', 'taxes', 'treasury')\n",
      "GROUP by a.docid order by sum_count desc \n",
      "limit 5\n",
      ";\n",
      "\"\"\"\n",
      "print cursor.execute(sql).fetchall()\n",
      "\n",
      "file = open(\"keyword_search.txt\", \"wb\")\n",
      "\n",
      "file.write(\"6\")\n",
      "\n",
      "file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'16094_txt_trade', 6.0), (u'16357_txt_trade', 6.0), (u'19775_txt_interest', 6.0), (u'10623_txt_trade', 5.0), (u'5964_txt_trade', 5.0)]\n"
       ]
      }
     ],
     "prompt_number": 138
    }
   ],
   "metadata": {}
  }
 ]
}